{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Protecting against Reidentification Attacks with Differential Privacy\n",
        "\n",
        "In this notebook we show how differential privacy can be used to protect sensitive personal information against re-identification attacks. The identities of individuals might be revealed if an attacker is able to map anonymized records about individuals from a published dataset with information about these people from various sources. \n",
        "In this demo, the published anonymized dataset contains patient records. The attacker tries to identify individuals by leveraging basic demographic information like age and zip codes.\n",
        "We show that successful reidentification attacks are possible even when the sensitive data is published in an anonymized format. Then, we perform a second attack after protecting the sensitive data using a dataset synthesizer from the SmartNoise system.\n",
        "\n",
        "\n",
        "This demo is based on the following steps:\n",
        "\n",
        "1. Import of anonymized medical data set and the attacker's data collection\n",
        "2. Reidentification Attack I: Revealing identities from the anonymized data set \n",
        "3. Protecting the medical dataset with differential privacy using Multiple Weights Exponential Mechanism (MWEM)\n",
        "4. Validating the utility of the synthesized data set for statistical analyses\n",
        "5. Reidentification Attack II: Trying to reveal identities based on the differentially private version of the medical data set"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries, uncomment if needed\n",
        "!pip install faker zipcodes tqdm opendp-smartnoise z3-solver==4.8.9.0"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638399746473
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import logging\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import string\n",
        "import uuid\n",
        "import time\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import reident_tools as reident\n",
        "from opendp.smartnoise.synthesizers.mwem import MWEMSynthesizer\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638399801967
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import data sets\n",
        "Below, we are going to import three data sets:\n",
        "1. Public medical data set, containing k-anonymized demographic and sensitive medical information\n",
        "2. Attacker's data collection with basic demographic information\n",
        "3. Public medical data set preprocessed for the MWEM synthesizer"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Read files\n",
        "df_medical = pd.read_csv('data/data_medical.csv', sep=\",\", encoding=\"utf-8\").infer_objects()\n",
        "df_medical['Zip'] = df_medical['Zip'].astype(str)\n",
        "print('Anonymized dataset including sensitive medical information:')\n",
        "display(df_medical.iloc[:,1:].sample(8))\n",
        "df_demographic = pd.read_csv('data/data_demographic.csv', sep=\",\", encoding=\"utf-8\").infer_objects()\n",
        "print('Attacker`s data collection with basic demographic information:')\n",
        "df_demographic['Zip'] = df_demographic['Zip'].astype(str)\n",
        "display(df_demographic.iloc[:,1:].sample(8))\n",
        "df_medical_synth = pd.read_csv('data/data_medical_synthesizer.csv', sep=\",\", encoding=\"utf-8\").infer_objects()\n",
        "df_medical_synth['Zip'] = df_medical_synth['Zip'].astype(str)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638399811570
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above data sets also include a unique id for each record which is used to be able to count the number of identified records after the attack. This information is not used for performing the attack. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reidentification Attack I - Revealing identities from the anonymized data set\n",
        "Below, we perform the first reidentification attack usind the `try_reidentification` function. As input, we use the data sets generated above (published medical and demographic data)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform the attack\n",
        "Now, we perform the reidentification attack with the demographic and the medical data set, using a combinatorial approach.\n",
        "\n",
        "**TIP**\n",
        "\n",
        "The following cell takes several minutes to complete. Start the execution of the cell first and then try to understand the details of the code being executed.\n",
        "The `try_reidentification` method is implemented in the `reident_tools.py` file."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "reident_attack = reident.try_reidentification(df_demographic, df_medical, logger)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results of the attack\n",
        "Below, we show the amount of potential and actual matches and provide a glance at the data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Found: {len(reident_attack[reident_attack[\"ID_Match\"]==True])} actual (validated) matches!')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638400488988
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write to file, if wanted\n",
        "# reident_attack.to_csv('data/results_reident-attack-raw.csv', sep=\",\", encoding=\"utf-8\", index=False)\n",
        "# Or read files, if needed\n",
        "# reident_attack = pd.read_csv('data/results_reident-attack-raw.csv', sep=\",\", encoding=\"utf-8\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1607612735291
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get sample from the data set\n",
        "print(f'Sample of re-identified patients:')\n",
        "reident_attack[reident_attack[\"ID_Match\"]==True][['Name', 'Gender', 'Age', 'Zip', 'Diagnosis', 'Treatment', 'Outcome', 'ID_Match']].sample(10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638400496809
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Protecting the medical dataset with differential privacy\n",
        "In the next step, we are going to synthesize the data set to increase the level of protection. We will use the Multiple Weights Exponential Mechanism (MWEM) synthesizer for this purpose and encode the demographic data (gender, age, zip) and the diagnosis. The other variables (treatment, outcome) are not part of the analysis for now."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data set for reidentification, using the medical data set and the full zip copied from the demographic set\n",
        "df_reident_synth = df_medical[['Gender', 'Age', 'Zip', 'Diagnosis', 'Treatment', 'Outcome']].copy()\n",
        "df_reident_synth['Zip'] = df_demographic['Zip'].copy()\n",
        "df_reident_synth['Age'] = df_demographic['Age'].copy()\n",
        "# Write to file, if wanted\n",
        "# df_reident_synth.to_csv('data/data_reidentification_synthesizer.csv', sep=\",\", encoding=\"utf-8\", index=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638400503431
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding of data\n",
        "For this purpose, we encode the input data using the `do_encode`-function to make it compatible with the MWEM synthesizer."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Have a quick glance at the data\n",
        "df_reident_synth.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638400508194
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the data set and display it\n",
        "df_reident_encoded = reident.do_encode(df_reident_synth, ['Gender', 'Age', 'Zip', 'Diagnosis'], reident.diseases)\n",
        "df_reident_encoded.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638400513114
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Synthesizing the demographic data\n",
        "Finally, we synthesize the data with the MWEM synthesizer. Here are some considerations regarding the parameters:\n",
        "- `Q_count` Should be higher than the number of iterations (at least 5 and 10 times the number of iterations). Default is 400.\n",
        "- `epsilon`The privacy parameter. 3.0 is a good starting point. Lower values correspond to higher levels of privacy.\n",
        "- `iterations` Comparable to epochs in deep learning. Between 30 and 60. Fewer iterations means that the budget is used more efficiently. Default is 30.\n",
        "- `mult_weights_iterations` Should be less than number of total iterations (usually between 5 and 50). Default is 20.\n",
        "- `splits` MWEM will automatically split the features with split factor if this field isnâ€™t specified. This field overrides split_factor, and creates custom user specified splits of features i.e. for a set with 5 features, [[0,3],[1,2,4]] (implies that features 0 and 3 are correlated, and features 1,2 and 4 are correlated).\n",
        "- `split_factor` Choose highest split factor without affecting performance. Start with number of features, then subdivide by 2 (round up)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Apply the synthesizer to the data set\n",
        "synthetic_data = MWEMSynthesizer(q_count = 400,\n",
        "                        epsilon = 3.00,\n",
        "                        iterations = 60,\n",
        "                        mult_weights_iterations = 40,\n",
        "                        splits = [],\n",
        "                        split_factor = 1)\n",
        "synthetic_data.fit(df_reident_encoded.to_numpy())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Convert to dataframe\n",
        "df_synthesized = pd.DataFrame(synthetic_data.sample(int(df_reident_encoded.shape[0])), columns=df_reident_encoded.columns)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Write it to file, if wanted\n",
        "# df_synthesized.to_csv('data/data_synthesized.csv', sep=\",\", encoding=\"utf-8\", index=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1607616212916
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare original and synthetic data\n",
        "Below, we are going to use the `create_histogram` function to illustrate the __diagnoses__ distribution of both data sets. \n",
        "Ideally, the bars for each diagnosis do not differ too much from each other. The more similar the bars are for the respective disease, the less information is lost during the synthetization process."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "reident.create_histogram(df_reident_encoded, df_synthesized, 'Diagnosis_encoded', reident.diseases)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638400552004
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reidentification Attack II - Synthesized Demographic Data + Public Medical Data (non-grouped)\n",
        "Finally, we try the re-identification attack on the synthesized data using the `try_reidentification_noise`-function.\n",
        "As stated above, the synthesized data set has new combinations of demographic data, so we do not deal with the _raw/real_ data any more. While it is possible that a potential match is detected, it is unlikely that we deal with an actual match here."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print('Medical Dataset:')\n",
        "display(df_medical_synth.sample(5))\n",
        "print('\\nSynthesized Demographic Dataset:')\n",
        "display(df_synthesized.sample(5))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638400564689
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform the attack\n",
        "Now, we perform the reidentification attack with the synthetic data, again using a combinatorial approach.\n",
        "\n",
        "**TIP**\n",
        "\n",
        "The following cell takes several minutes to complete. Start the execution of the cell first and then try to understand the details of the code being executed.\n",
        "The `try_reidentification_noise` method is implemented in the `reident_tools.py` file."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "reident_attack_2 = reident.try_reidentification_noise(df_synthesized, df_medical_synth, logger)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638400789447
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results of the attack\n",
        "Below, we show the amount of potential and actual matches and provide a glance at the data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Found {len(reident_attack_2)} potential matches!')\n",
        "reident_attack_2.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1638400816543
        }
      }
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "7db80ffa0fa6d2241722faa1625c6f6ec2c5ee2efca66be1a48044e9e0db9c67"
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}