{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab04 - Deploying a real-time scoring endpoint with managed compute\r\n",
        "\r\n",
        "Azure Machine Learning allows you to set a **real-time endpoint**, when you need to get an immediate response when using your model (Online recommendation, fraud detection, etc...).\r\n",
        "\r\n",
        "For a real-time solution, very often, you will need to deploy it on some 24/7 up and running compute instance properly dimensioned. So you will need to choose carefully on which compute to deploy.\r\n",
        "\r\n",
        "*To illustrate this*, in this lab we will:\r\n",
        "\r\n",
        " . **Train** a model\r\n",
        "\r\n",
        " . **Test** this model with a local deployment\r\n",
        "\r\n",
        " . **Deploy** your model for real-life scenario.\r\n",
        "\r\n",
        "\r\n",
        " *More specifically, the deployment part of this Lab will cover*:\r\n",
        "- The notion of Azure ML `Environments`, that allows to deploy on:\r\n",
        "    - 1. Reproductible contexts.\r\n",
        "    - 2. Customizable contexts.\r\n",
        "        - Via custom Docker images\r\n",
        "        - Via a requirement.txt file\r\n",
        "- [Which compute](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=azcli#choose-a-compute-target) depending on the purpose of your deployment\r\n",
        "    - Local deployment for development purposes.\r\n",
        "    - Deployment on scalable environments, as we are setting here a real-time service endpoint, so that your model can be used remotely, and respond immediately\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1 - Train a Classifier\r\n",
        "\r\n",
        "## Task 1 - Let's observe and prepare the data\r\n",
        "\r\n",
        "**Import required libraries**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\r\n",
        "import sys\r\n",
        "import os\r\n",
        "import pip\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import requests\r\n",
        "import sklearn\r\n",
        "\r\n",
        "def installFromNotebook(package):\r\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\r\n",
        "\r\n",
        "def upgradeFromNotebook(package):\r\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", package])\r\n",
        "\r\n",
        "#Verification that the SDK is up to date\r\n",
        "upgradeFromNotebook(\"azureml-sdk\")\r\n",
        "import azureml.core\r\n",
        "from azureml.core import Dataset\r\n",
        "from azureml.core import Workspace\r\n",
        "ws = Workspace.from_config()\r\n",
        "\r\n",
        "#Installing other dependancies\r\n",
        "installFromNotebook(\"plotly\")\r\n",
        "import plotly.express as px\r\n",
        "import plotly.graph_objs as go\r\n",
        "import plotly.figure_factory as ff\r\n",
        "plt.style.use(\"classic\")\r\n",
        "\r\n",
        "#Create path to have outputs folder and outputs/models to store our models\r\n",
        "try:\r\n",
        "    os.makedirs(r'./outputs/models/')\r\n",
        "except:\r\n",
        "     pass\r\n",
        "try:\r\n",
        "    os.makedirs(r'./sources/')\r\n",
        "except:\r\n",
        "     pass\r\n",
        "try:\r\n",
        "    os.makedirs(r'./data/')\r\n",
        "except:\r\n",
        "     pass\r\n",
        "\r\n",
        "#Sanity check on version and Workspace name\r\n",
        "print(\"Libs version control --\", \"Azure ML SDK Version:\", azureml.core.VERSION, \"Pandas:\", pd.__version__, \"pip:\", pip.__version__,\r\n",
        "\"seaborn:\", sns.__version__, 'Scikit-kearn:', sklearn.__version__, 'Workspace:', ws.name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633334271218
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset overview: Covid-19 Case Surveillance Public Use Dataset\r\n",
        "\r\n",
        "## General considerations\r\n",
        "\r\n",
        "https://data.cdc.gov/Case-Surveillance/COVID-19-Case-Surveillance-Public-Use-Data/vbim-akqf\r\n",
        "\r\n",
        "The COVID-19 case surveillance system database includes individual-level data reported to U.S. states and autonomous reporting entities, including New York City and the District of Columbia (D.C.), as well as U.S. territories and states. On April 5, 2020, COVID-19 was added to the Nationally Notifiable Condition List and classified as “immediately notifiable, urgent (within 24 hours)” by a Council of State and Territorial Epidemiologists (CSTE) Interim Position Statement (Interim-20-ID-01). CSTE updated the position statement on August 5, 2020 to clarify the interpretation of antigen detection tests and serologic test results within the case classification. The statement also recommended that all states and territories enact laws to make COVID-19 reportable in their jurisdiction, and that jurisdictions conducting surveillance should submit case notifications to CDC. COVID-19 case surveillance data are collected by jurisdictions and shared voluntarily with CDC.\r\n",
        "\r\n",
        "For more information: wwwn.cdc.gov/nndss/conditions/coronavirus-disease-2019-covid-19/case-definition/2020/08/05/.\r\n",
        "\r\n",
        "The dataset contains 13.4 million rows of deidentified patient data (more than 3 Go). To run this lab smoothly, we will use an extract of 100.000 data point.\r\n",
        "\r\n",
        "## Data points description\r\n",
        "\r\n",
        "| Variable        | Description      | Source        | Values        | Type\t        | Calculation (if applicable)      |\r\n",
        "| ------|-----|-----|-----|-----|-----|\r\n",
        "| **cdc_report_dt**  \t| Date case was first reported to the CDC \t| Calculated \t| YYYY-MM-DD \t| Date \t| Deprecated; CDC recommends researchers use cdc_case_earliest_dt in time series and other analyses. This date was populated using the date at which a case record was first submitted to the database. If missing, then the report date entered on the case report form was used. If missing, then the date at which the case first appeared in the database was used. If none available, then left blank.  \t|\r\n",
        "| **cdc_case_earliest_dt**  \t| The earlier of the Clinical Date (date related to the illness or specimen collection) or the Date Received by CDC \t| Calculated \t| YYYY-MM-DD \t| Date \t| Cdc_case_earliest_dt uses the best available date from the set of dates related to illness/specimen collection and the set of dates related to when a case is reported. It is an option to end-users who need a date variable with optimized completeness. The logic of cdc_case_earliest_dt is to use the non-null date of one variable when the other is null and to use the earliest valid date when both dates are available.  If no date available, then left blank. \t|\r\n",
        "| **pos_spec_dt**  \t| Date of first positive specimen collection \t| Case Report Form \t| YYYY-MM-DD \t| Date \t|  \t|\r\n",
        "| **onset_dt**  \t| Date of symptom onset \t| Case Report Form \t| YYYY-MM-DD \t| Date \t|  \t|\r\n",
        "| **current_status**  \t| What is the current status of this person? \t| Case Report Form \t| Laboratory-confirmed case Probable case \t| String \t| Please see latest CSTE case definition for more information. \t|\r\n",
        "| **sex**  \t| Gender \t| Case Report Form \t| [Male - Female - Unknown - Other - Missing - NA] \t| String \t|  \t|\r\n",
        "| **age_group**  \t| Age group categories \t| Calculated \t| [0 - 9 Years - 10 - 19 Years - 20 - 39 Years - 40 - 49 Years - 50 - 59 Years - 60 - 69 Years - 70 - 79 Years - 80 + Years - Missing - NA] \t| String \t| The age group categorizations were populated using the age value that was reported on the case report form. Date of birth was used to fill in missing/unknown age values using the difference in time between date of birth and onset date. \t|\r\n",
        "| **race_ethnicity_combined**  \t| Race and Ethnicity (combined) \t| Calculated \t| [American Indian/Alaska Native, Non-Hispanic - Asian, Non-Hispanic - Black, Non-Hispanic - Multiple/Other, Non-Hispanic - Native Hawaiian/Other Pacific Islander, Non-Hispanic - White, Non-Hispanic - Hispanic/Latino - Unknown - Missing - NA] \t| String \t| If more than race was reported, race was categorized into multiple/other races. \t|\r\n",
        "| **hosp_yn**  \t| Was the patient hospitalized? \t| Case Report Form \t| [Yes - No - Unknown - Missing] \t| Character \t|  \t|\r\n",
        "| **icu_yn**  \t| Was the patient admitted to an intensive care unit (ICU)? \t| Case Report Form \t| [Yes - No - Unknown - Missing] \t| Character \t|  \t|\r\n",
        "| **death_yn**  \t| Did the patient die as a result of this illness? \t| Case Report Form \t| [Yes - No - Unknown - Missing] \t| Character \t|  \t|\r\n",
        "| **medcond_yn**  \t| Pre-existing medical conditions? \t| Case Report Form \t| [Yes - No - Unknown - Missing] \t| Character \t|  \t|"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First overview of raw data\r\n",
        "\r\n",
        "Here we will grab some raw data from the dataset, quickly available online, to have a first overview."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get a fraction of the dataset (to observe the first rows rapidly)\r\n",
        "Covid19_CSPUD_JSON = requests.get('https://data.cdc.gov/resource/vbim-akqf.json')\r\n",
        "data = pd.read_json(Covid19_CSPUD_JSON.text)\r\n",
        "#Observe top 5 lines\r\n",
        "data.head(5)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633334395001
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the full extract of the dataset and observe in more detail\r\n",
        "\r\n",
        "Now we will get the extract of 100.000 lines from the full dataset, and look at:\r\n",
        " - How many null values for each variable, in order to see how many which one have missing data, and at which proportion.\r\n",
        " - How many single values for each variable to validate which variable should be categorical."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://solliancepublicdata.blob.core.windows.net/azure-ml-datascience/COVID-19_Case_Surveillance_Public_Use_Data_shuffled_100000.csv'\r\n",
        "data = pd.read_csv(url, error_bad_lines=False)\r\n",
        "\r\n",
        "#View columns where many data is missing\r\n",
        "print('>> Null count by variable \\r\\n')\r\n",
        "print(data.isnull().sum())\r\n",
        "\r\n",
        "#Now let's have a summarized look at our data\r\n",
        "print('\\r\\n>> Data general description (including unique values) \\r\\n')\r\n",
        "print(data.describe().transpose())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633334401784
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove uncomplete or deprecated columns (variables)\r\n",
        "\r\n",
        "In the data description, we have learned that 'cdc_report_dt' is deprecated and 'pos_spec_dt' and 'onset_dt' are way too incomplete, in regard to a total of 100.000 rows, to be used. So we remove those columns."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(['cdc_report_dt', 'pos_spec_dt', 'onset_dt'], axis=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633334409714
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observe the distributions among some categorical variables\r\n",
        "\r\n",
        "With Azure Machine Learning Python SDK, you can plot many types of chart to observe your dataset.\r\n",
        "\r\n",
        "We will plot for observation purposes the distributions of:\r\n",
        " - Statuses\r\n",
        " - Genders\r\n",
        " - Ages\r\n",
        " - Ethnicities\r\n",
        "\r\n",
        "We will also have a look at the death status by gender.\r\n",
        "\r\n",
        "Note that those charts also have some interactive features.\r\n",
        "\r\n",
        "![Charts interactivity](./images/LAB04-Charts-Interactivity.png)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##CONFIRMED CASES\r\n",
        "values = data['current_status'].value_counts().tolist()\r\n",
        "#Print unique status values\r\n",
        "print('\\r\\n\\t', '>> Unique cases status values:', data['current_status'].unique())\r\n",
        "#Use shorte names for thos values for display purposes\r\n",
        "names = ['Confirmed', 'Probable']\r\n",
        "\r\n",
        "#Make pie chart\r\n",
        "fig = px.pie(\r\n",
        "    names=names,\r\n",
        "    values=values,\r\n",
        "    title=\"Case Status Pie Chart\",\r\n",
        "    color_discrete_sequence=px.colors.sequential.RdBu,\r\n",
        ")\r\n",
        "#Display pie chart\r\n",
        "fig.show()\r\n",
        "\r\n",
        "##GENDER DISTRIBUTION\r\n",
        "values = data['sex'].value_counts().tolist()\r\n",
        "print('\\r\\n\\t', '>> Unique cases gender values:', data['sex'].unique())\r\n",
        "names = ['Female', 'Male', 'Unknown', 'Missing', 'Other']\r\n",
        "fig = px.pie(\r\n",
        "    names=names,\r\n",
        "    values=values,\r\n",
        "    title=\"Gender Status Distribution\",\r\n",
        "    color_discrete_sequence=px.colors.sequential.Bluyl_r,\r\n",
        ")\r\n",
        "fig.show()\r\n",
        "\r\n",
        "##AGE GROUP DISTRIBUTION\r\n",
        "values = data['age_group'].value_counts().tolist()\r\n",
        "print('\\r\\n\\t', '>> Age beans:', data['age_group'].unique())\r\n",
        "names = ['20 - 29 Years', '30 - 39 Years', '40 - 49 Years', '50 - 59 Years', '60 - 69 Years', '10 - 19 Years', '70 - 79 Years', '80+ Years', '0 - 9 Years', 'Unknown']\r\n",
        "fig = px.bar(\r\n",
        "    x=names,\r\n",
        "    y=values,\r\n",
        "    title=\"Age Group Distribution\",\r\n",
        "    labels={\r\n",
        "        'x': 'Age Group',\r\n",
        "        'y': 'Number of Patients'\r\n",
        "    },\r\n",
        "    color=values\r\n",
        ")\r\n",
        "fig.show()\r\n",
        "\r\n",
        "#ETHNICITY\r\n",
        "values = data['race_ethnicity_combined'].value_counts().tolist()\r\n",
        "print('\\r\\n\\t', '>> Race and ethnicity (combined):', data['race_ethnicity_combined'].unique())\r\n",
        "names = ['Unkown', 'White, Non-Hispanic', 'Hispanic/Latino', 'Black, Non-Hispanic', 'Missing', 'Multiple/Other, Non-Hispanic', 'Asian, Non-Hispanic', 'American Indian/Alaska Native, Non-Hispanic', 'Native Hawaiian/Other Pacific Islancer, Non-Hispanic']\r\n",
        "fig = px.pie(\r\n",
        "    names=names,\r\n",
        "    values=values,\r\n",
        "    title=\"Distribution of Races and Ethnicities \",\r\n",
        "    color_discrete_sequence=px.colors.sequential.Electric,\r\n",
        ")\r\n",
        "fig.show()\r\n",
        "\r\n",
        "#DEATH STATUS BY GENDER\r\n",
        "plt.figure(figsize=(9, 7))\r\n",
        "plt.style.use(\"fivethirtyeight\")\r\n",
        "sns.countplot(y=\"death_yn\", hue ='sex', data=data[data['sex'].isin(['Male', 'Female', 'Other'])])\r\n",
        "plt.xlabel(\"Count\")\r\n",
        "plt.ylabel(\"Death Status\")\r\n",
        "plt.title('Death Status by Gender')\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633334427239
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding the data for the machine\r\n",
        "\r\n",
        "Now we will encode the categorical data, assigning a numeric value to each element of the catagorical data.\r\n",
        "\r\n",
        "For instance, we have 10 distinct age groups, whose values are strings (e.g.: '0 - 9 Years').\r\n",
        "\r\n",
        "To facilitate the use of those variables for some machine learning algorithms, '0 - 9 Years' could be turned to 0 and '10 - 19 Years' could be turned to 1, to use numeric values for those categorical variables, instead of strings."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "lb_encoder = LabelEncoder()\r\n",
        "data['current_status'] = lb_encoder.fit_transform(data['current_status'])\r\n",
        "data['age_group'] = lb_encoder.fit_transform(data['age_group'])\r\n",
        "data['race_ethnicity_combined'] = lb_encoder.fit_transform(data['race_ethnicity_combined'])\r\n",
        "data['sex'] = lb_encoder.fit_transform(data['sex'])\r\n",
        "data['hosp_yn'] = lb_encoder.fit_transform(data['hosp_yn'])\r\n",
        "data['icu_yn'] = lb_encoder.fit_transform(data['icu_yn'])\r\n",
        "data['death_yn'] = lb_encoder.fit_transform(data['death_yn'])\r\n",
        "data['medcond_yn'] = lb_encoder.fit_transform(data['medcond_yn'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633334448211
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Storing the dataset once prepared\r\n",
        "\r\n",
        "### Store in a variable for immadiate reuse"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Store exploitable data variable to use it in other NoteBooks\r\n",
        "%store data\r\n",
        "data.head(5)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633334451428
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register the dataset for more permanent purposes\r\n",
        "\r\n",
        "For proper handeling and reuse. Once registered, you can find your dataset in the \"Datasets\" menu of the interface.\r\n",
        "\r\n",
        "![Registered datasets](./images/LAB04-Registered-datasets.png)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datastore = ws.get_default_datastore()\r\n",
        "\r\n",
        "data.to_csv('./data/COVID_19_CSPUD_100k.csv')\r\n",
        "\r\n",
        "datastore.upload(src_dir='./data/', target_path='./data/')\r\n",
        "\r\n",
        "dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, './data/')])\r\n",
        "\r\n",
        "COVID_19_CSPUD_100k = dataset.register(workspace=ws,\r\n",
        "                                 name='COVID_19_CSPUD_100k',\r\n",
        "                                 description='COVID-19 Case Surveillance Public Use Data')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633334481271
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2 - Train models and record the best one\r\n",
        "\r\n",
        "### Load models from the Python library Scikit Learn"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scikit-learn machine learning models\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.svm import SVC, LinearSVC\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.linear_model import Perceptron\r\n",
        "from sklearn.linear_model import SGDClassifier\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "#Scikit-learn data split\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn import metrics\r\n",
        "#To serialize models\r\n",
        "import pickle as pkl\r\n",
        "\r\n",
        "from azureml.core.model import Model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633334503193
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the data and split them in training set and test set\r\n",
        "\r\n",
        "Note that we will not take the 'Unknown' or 'Missing' death status to train our model.\r\n",
        "\r\n",
        "Also, we will not take ethnicity, who ads a lot of complexity, for only 80k lines (i.e. 80k data points)\r\n",
        "\r\n",
        "Once loaded, we will check the dimentions of each set in order to validate we fit the expected format."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the data variable stored at the end of the data preparation\r\n",
        "%store -r data\r\n",
        "data.head(5)\r\n",
        "\r\n",
        "X = data.query('death_yn in [0, 1]')[['current_status', 'sex', 'age_group', 'hosp_yn','icu_yn','medcond_yn']]\r\n",
        "y = data.query('death_yn in [0, 1]')['death_yn']\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\r\n",
        "\r\n",
        "#Dimensions sanity check\r\n",
        "print('> X_train dimensions:', X_train.shape, '\\r\\n> X_test dimensions', X_test.shape, '\\r\\n> y_train dimensions', y_train.shape, '\\r\\n> y_test dimensions', y_test.shape)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633334509387
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instantiate the ML algorithms we have chosen"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg = LogisticRegression(solver='lbfgs', max_iter=1500) #lbfgs is default but to ensure it remains the same, \r\n",
        "                                                            #playing around with iterations, for convergence purposes\r\n",
        "svc = SVC()\r\n",
        "lin_svc = LinearSVC(max_iter=10000)\r\n",
        "rfc = RandomForestClassifier()\r\n",
        "knn = KNeighborsClassifier()\r\n",
        "gnb = GaussianNB()\r\n",
        "perceptron = Perceptron()\r\n",
        "sdg = SGDClassifier()\r\n",
        "dtc = DecisionTreeClassifier()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633334515497
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's learn\r\n",
        "\r\n",
        "Each algorithm will now try to determine a function f(X) -> y that best fits the Xs and ys.\r\n",
        "\r\n",
        "*Note*: **It make take around 6 minutes**."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Algorithms fitting/learning\r\n",
        "log_reg.fit(X_train, y_train)\r\n",
        "svc.fit(X_train, y_train)\r\n",
        "lin_svc.fit(X_train, y_train)\r\n",
        "rfc.fit(X_train, y_train)\r\n",
        "knn.fit(X_train, y_train)\r\n",
        "gnb.fit(X_train, y_train)\r\n",
        "perceptron.fit(X_train, y_train)\r\n",
        "sdg.fit(X_train, y_train)\r\n",
        "dtc.fit(X_train, y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633334834467
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate the models\r\n",
        "\r\n",
        "#### Step 1: Make predictions on the test set\r\n",
        "\r\n",
        "Now each model has determined a function, we will try to evaluate the most valuable function according to our needs.\r\n",
        "\r\n",
        "To do so we will make, for each function, some predictions on the test dataset and score those predictions.\r\n",
        "\r\n",
        "So we will use the F1-score (weighted average between our two relatively balanced classes) to choose our \"best\" model, and the F1 given by the sklearn metrics we used in the Notebook takes by default a good balance between precision and recall.\r\n",
        "\r\n",
        "*Note*: Once we will use the classifier for a real case scenario, you can use the .predict_proba() method in order to get an intuition about the level of risk for this patient"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Make predictions on the test dataset for a first model\r\n",
        "y_pred = log_reg.predict(X_test)\r\n",
        "#Then score this model\r\n",
        "print('> Classification report Logistic regression\\r\\n', metrics.classification_report(y_test, y_pred), '\\r\\n')\r\n",
        "\r\n",
        "#Then we do this for all the models\r\n",
        "y_pred = svc.predict(X_test)\r\n",
        "print('> Classification report Support Vector Machine (optim 1)\\r\\n', metrics.classification_report(y_test, y_pred), '\\r\\n')\r\n",
        "\r\n",
        "y_pred = lin_svc.predict(X_test)\r\n",
        "print('> Classification report Support Vector Machine (optim 2)\\r\\n', metrics.classification_report(y_test, y_pred), '\\r\\n')\r\n",
        "\r\n",
        "y_pred = rfc.predict(X_test)\r\n",
        "print('> Classification report Random Forest\\r\\n', metrics.classification_report(y_test, y_pred), '\\r\\n')\r\n",
        "\r\n",
        "y_pred = knn.predict(X_test)\r\n",
        "print('> Classification report k-Nearest Neighbours\\r\\n', metrics.classification_report(y_test, y_pred), '\\r\\n')\r\n",
        "\r\n",
        "y_pred = gnb.predict(X_test)\r\n",
        "print('> Classification report Gaussian Naïve Bayes\\r\\n', metrics.classification_report(y_test, y_pred), '\\r\\n')\r\n",
        "\r\n",
        "y_pred = perceptron.predict(X_test)\r\n",
        "print('> Classification report Perceptron\\r\\n', metrics.classification_report(y_test, y_pred), '\\r\\n')\r\n",
        "\r\n",
        "y_pred = sdg.predict(X_test)\r\n",
        "print('> Classification report Mixed Linear Models\\r\\n', metrics.classification_report(y_test, y_pred), '\\r\\n')\r\n",
        "\r\n",
        "y_pred = dtc.predict(X_test)\r\n",
        "print('> Classification report Decision Tree\\r\\n', metrics.classification_report(y_test, y_pred), '\\r\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633336669450
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2: Plot the ROC curves for each model\r\n",
        "\r\n",
        "As the F1-score is the same for some of the models, and as it (the F1-score) is applicable on any point of the ROC curve, then we will look at the AUC (area under the ROC curve) and take the biggest AUC, sort of generalization of the F1 for all precision/recall threshold values."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Verify our data are balanced\r\n",
        "print('> Data balance', data.query('death_yn in [0, 1]')['death_yn'].mean(), '\\r\\n')\r\n",
        "\r\n",
        "#Plot the ROC curve\r\n",
        "metrics.plot_roc_curve(log_reg, X_test, y_test)\r\n",
        "metrics.plot_roc_curve(svc, X_test, y_test)\r\n",
        "metrics.plot_roc_curve(lin_svc, X_test, y_test)\r\n",
        "metrics.plot_roc_curve(rfc, X_test, y_test)\r\n",
        "metrics.plot_roc_curve(knn, X_test, y_test)\r\n",
        "metrics.plot_roc_curve(gnb, X_test, y_test)\r\n",
        "metrics.plot_roc_curve(perceptron, X_test, y_test)\r\n",
        "metrics.plot_roc_curve(sdg, X_test, y_test)\r\n",
        "metrics.plot_roc_curve(dtc, X_test, y_test)\r\n",
        "\r\n",
        "#Precision: How many (which proportion) selected elements are pertinents\r\n",
        "#Recall: How many (which proportion) pertinent elements has been selected\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633336844220
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Store a serialized version of your best model\r\n",
        "\r\n",
        "Once chosen a model, you can record a serialized version of it with the Python's `Pickle` library, and save it as a file you can reuse later on."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SAVE THE BEST MODEL---------------------------------\r\n",
        "#Save a serialized version of your models\r\n",
        "pkl.dump(dtc, open(r'./outputs/models/DecisionTreeClassifier.pkl', 'wb'))\r\n",
        "#----------------------------------------------------"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633336852783
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register your model\r\n",
        "\r\n",
        "You can now record this model, properly handled and version in the \"Models\" section of this interface.\r\n",
        "\r\n",
        "![Registered models](./images/LAB04-Registered-models.png)\r\n",
        "\r\n",
        "[From Microsoft documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.model?view=azure-ml-py): Registering a model creates a logical container for the one or more files that make up your model. In addition to the content of the model file itself, a registered model also stores model metadata, including model description, tags, and framework information, that is useful when managing and deploying the model in your workspace. For example, with tags you can categorize your models and apply filters when listing models in your workspace. After registration, you can then download or deploy the registered model and receive all the files and metadata that were registered."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model.register(model_path=r'./outputs/models/DecisionTreeClassifier.pkl',\r\n",
        "                       model_name=\"DecisionTreeClassifier\",\r\n",
        "                       tags={'area': 'covid19', 'type': 'classification'},\r\n",
        "                       description='Survival to Covid-19 classification and estimation',\r\n",
        "                       workspace=ws)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633336868562
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2 - Create an Azure ML prebuilt Docker container image for scoring\r\n",
        "\r\n",
        "## Task 1 - Test locally with Local Web service Compute target\r\n",
        "\r\n",
        "#### Script to test the deployment and the model\r\n",
        "\r\n",
        "Note that %%writefile is NOT a Python magic but a command of Jupyter Notebook. Avoid commenting before the %%writefile command, it would break the behavior of this command."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ./sources/scoring_script.py\r\n",
        "\r\n",
        "import json\r\n",
        "import pickle as pkl\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "def init():\r\n",
        "    from azureml.core.model import Model\r\n",
        "    global model\r\n",
        "    model_name = 'DecisionTreeClassifier'\r\n",
        "    model_path = Model.get_model_path(model_name=model_name)\r\n",
        "    model = pkl.load(open(model_path, 'rb'))\r\n",
        "\r\n",
        "def run(data):\r\n",
        "    test = json.loads(data)\r\n",
        "    result = model.predict(np.array(test[\"X_test\"]).reshape(-1, 6)).tolist()\r\n",
        "    return result"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set an environment for your service\r\n",
        "\r\n",
        "In order to get reproductible development and testing experiences, Azure Machine Learning let you define some [Environments](https://docs.microsoft.com/en-us/azure/machine-learning/concept-environments) that will encapsulate all the elements you need to develop or/and run your applications within a well defined and reproductible context.\r\n",
        "\r\n",
        "Azure Machine Learning propose plug and play curated environments, but you can also create our own and personalize everything.\r\n",
        "\r\n",
        "![Environment description](./images/LAB04-Environment-description.png)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Environment\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.environment import CondaDependencies\r\n",
        "\r\n",
        "env = Environment(name='lab04_environment')\r\n",
        "conda_dep = CondaDependencies()\r\n",
        "conda_dep.add_conda_package(\"scikit-learn\")\r\n",
        "conda_dep.add_conda_package(\"pandas\")\r\n",
        "env.python.conda_dependencies=conda_dep\r\n",
        "#Register your custom environment for further use\r\n",
        "env.register(workspace=ws)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633336947563
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now **look at the output field \"baseImage\"**. You will see that Azure Machine Leaning used defaultly a docker image to create your environment.\r\n",
        "\r\n",
        "You can also observe the \"Environments\" page of the interface and observe the last version created. On the top right side of the screen you will see the default Docker image used for this environment.\r\n",
        "\r\n",
        "![Environment Docker Image](./images/LAB04-Environment-Docker-Image.png)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inference configuration\r\n",
        "\r\n",
        "Here you will define on which environment your inference service will take place, and what script should be used to run it."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inference configuration (docker image, environment of the inference service)\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "\r\n",
        "lab04_inference_config = InferenceConfig(\r\n",
        "    environment=env,\r\n",
        "    source_directory='./sources/',\r\n",
        "    entry_script='scoring_script.py',\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633337669664
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compute configuration\r\n",
        "\r\n",
        "Now you have to choose on which compute / machine(s) you want your service to run on.\r\n",
        "\r\n",
        "Be careful and choose at least some compute that will be coherent - i.e. big enough - with the environment and inference configuration you have chosen before.\r\n",
        "\r\n",
        "Also, depending on the fact that it's fort testings purposes, or live production service, you may want to choose different types and different sizes of computes in order to ensure your service will manage properly the expected workload.\r\n",
        "\r\n",
        "*Note*: In case you do not have the [compute target](https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target) you need already set, if your subscription is properly provisioned, Azure Machine Learning will allow you to create this compute target right away with just a few lines of Python code.\r\n",
        "\r\n",
        "The purpose right now is to test the service, so we will use our local compute which will be big enough."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#deployment configuration (machine size, CPU, GPU, i.e. the compute target requested by your Web Service)\r\n",
        "from azureml.core.webservice import LocalWebservice\r\n",
        "\r\n",
        "deployment_config = LocalWebservice.deploy_configuration(port=6789)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633337674114
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Deploy your service\r\n",
        "\r\n",
        "Here we deploy locally for testings purposes"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Deployment : Genreates a Docker build context\r\n",
        "service = Model.deploy(\r\n",
        "    ws,\r\n",
        "    'covid19-survival-pred-local-test',\r\n",
        "    [model],\r\n",
        "    lab04_inference_config,\r\n",
        "    deployment_config,\r\n",
        "    overwrite=True,\r\n",
        ")\r\n",
        "service.wait_for_deployment(show_output=True)\r\n",
        "\r\n",
        "#Deployment logs\r\n",
        "print(service.get_logs())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633337723181
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now **open the terminal and run the following command**:\r\n",
        "\r\n",
        "*curl -X POST -d '{\"X_test\":\\[0, 1, 2, 1, 0, 1\\]}' -H \"Content-Type: application/json\" http://localhost:6789/score*\r\n",
        "\r\n",
        "Now try with someone way older (change the \"2\" - age bean 20-30 by an \"8\" - age bean for the 80+ years old) and you will observe that the odds about survival are not the same.\r\n",
        "*curl -X POST -d '{\"X_test\":\\[0, 1, 8, 1, 0, 1\\]}' -H \"Content-Type: application/json\" http://localhost:6789/score*\r\n",
        "\r\n",
        "*Note*: Just as a reminder, the values passed in the list for the inference are (in this order): \\[current_status, sex, age_group, hosp_yn, icu_yn, medcond_yn\\]"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2 - Deploy on managed compute and test live\r\n",
        "\r\n",
        "Now you are fine with your model, you can deploy it on production so that the client can start using it.\r\n",
        "\r\n",
        "The recommended Compute targets for this are [Azure Kubernetes Service (AKS)](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-azure-kubernetes-service?tabs=python) (AKS) for high-scale production deployments, or [Azure Container Instances](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-azure-container-instance) (ACI) for low-scale scenarios.\r\n",
        "\r\n",
        "We want to deploy some real-time scoring solutions. Machines have to be up-and-running 24/7 and give immediate responses. So will choose AKS. When the deployment is done with the Python Notebook, you can observe your endpoint and its settings.\r\n",
        "\r\n",
        "*Note*: **It make take between 10 and 25 minutes**."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AksCompute, ComputeTarget\r\n",
        "from azureml.core.webservice import AksWebservice\r\n",
        "\r\n",
        "# Use the default configuration (you can also provide parameters to customize this)\r\n",
        "prov_config = AksCompute.provisioning_configuration()\r\n",
        "\r\n",
        "aks_name = 'akscovidcluster'\r\n",
        "# Create the cluster\r\n",
        "aks_target = ComputeTarget.create(workspace = ws,\r\n",
        "                                    name = aks_name,\r\n",
        "                                    provisioning_configuration = prov_config)\r\n",
        "\r\n",
        "# Wait for the create process to complete\r\n",
        "aks_target.wait_for_completion(show_output = True)\r\n",
        "\r\n",
        "aks_target = AksCompute(ws, aks_name)\r\n",
        "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\r\n",
        "service = Model.deploy(ws, 'akscovidservice', [model], lab04_inference_config, deployment_config, aks_target)\r\n",
        "service.wait_for_deployment(show_output = True)\r\n",
        "print(service.state)\r\n",
        "print(service.get_logs())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633338372942
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now **go to \"Compute\", then open the \"Inference clusters\" tab** from the interface.\r\n",
        "\r\n",
        "You can see that a new compute named \"akscovidcluster\", dedicated to your real-time inference service, has been deployed and is now up and running. We will test in the next paragraph, that your service works properly on it.\r\n",
        "\r\n",
        "![Inference Cluster Compute](./images/LAB04-Inference-cluster-compute.png)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test quickly from the interface\r\n",
        "\r\n",
        "Now go to the test interface of your newly created real-time endpoint, named \"akscovidservice\", choose the \"Test\" tab, and copy / paste the following data in the capture box: *{\"X_test\":\\[0, 1, 2, 1, 0, 1\\]}*\r\n",
        "\r\n",
        "*Note*: Just as a reminder, the values passed in the list for the inference are (in this order): \\[current_status, sex, age_group, hosp_yn, icu_yn, medcond_yn\\]\r\n",
        "\r\n",
        "![Test real-time endpoint directly from the Azure interface](./images/LAB04-13-Test-real-time-endpoint-AKS.png)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test as an integrated solution: call your Web Service in Python\r\n",
        "\r\n",
        "**BEWARE**: You will have to **change the api_key with your own one**. You can find it when you edit your endpoint and open the \"Consume\" tab. The api_key is named under \"Primary key\". You can for security purposes regenerate it. When you do that, you can use the second key temporarily while the primary one is re-generating, in order to not interrupt your service.\r\n",
        "\r\n",
        "![LAB04 Api key to use endpoint](./images/LAB04-Api-key-to-use-endpoint.png)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\r\n",
        "import json\r\n",
        "import os\r\n",
        "import ssl\r\n",
        "\r\n",
        "def allowSelfSignedHttps(allowed):\r\n",
        "    # bypass the server certificate verification on client side\r\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\r\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\r\n",
        "\r\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\r\n",
        "\r\n",
        "# Request data goes here\r\n",
        "data = {\"X_test\":[0, 1, 2, 1, 0, 1]}\r\n",
        "\r\n",
        "body = str.encode(json.dumps(data))\r\n",
        "\r\n",
        "url = 'http://20.61.110.142:80/api/v1/service/akscovidservice/score' # Replace this with the URL for the web service. This one is fake, for illustrative purposes only.\r\n",
        "api_key = 'lL6jj02r4L5CVZ2PiLAhbjyAybtNAJ3T' # Replace this with the API key for the web service. This one is fake, for illustrative purposes only.\r\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\r\n",
        "\r\n",
        "req = urllib.request.Request(url, body, headers)\r\n",
        "\r\n",
        "try:\r\n",
        "    response = urllib.request.urlopen(req)\r\n",
        "\r\n",
        "    result = response.read()\r\n",
        "    print(result)\r\n",
        "except urllib.error.HTTPError as error:\r\n",
        "    print(\"The request failed with status code: \" + str(error.code))\r\n",
        "\r\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\r\n",
        "    print(error.info())\r\n",
        "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633340138033
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3 - Deploy custom Docker container image with managed compute\r\n",
        "\r\n",
        "## Task 1 - Deploy custom Docker container image with managed compute\r\n",
        "\r\n",
        "Now that we have seen local deployments for development purposes.\r\n",
        "\r\n",
        "Now we also have seen how to deploy your service to production environments.\r\n",
        "\r\n",
        "We will see that those environments can be easily customized."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a custom Docker container image\r\n",
        "\r\n",
        "*Note* that you can also cherry-pick among the Docker images provided by Azure. We recommend custom Docker images in case you need to install non-Python packages as dependencies"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#WRITE YOUR DOCKER FILE------------------------------\r\n",
        "#Note that the dockerfile is here written as a string and not as a file.\r\n",
        "#It works as well, and for more permanent, usual and collabotrative process\r\n",
        "#we would rather recommend that you write it down as a file containing all\r\n",
        "#these steps in a more permanent and \"portable\" location. Anyway it will be done\r\n",
        "#when you will register your environment\r\n",
        "dockerfile = r\"\"\"\r\n",
        "FROM mcr.microsoft.com/mlops/python:latest\r\n",
        "#Install the dependancies\r\n",
        "RUN pip install --no-cache-dir --upgrade pip && \\\r\n",
        "    pip install --no-cache-dir azureml-defaults && \\\r\n",
        "    pip install --no-cache-dir azureml-core==1.27.0 &&\\\r\n",
        "    pip install --no-cache-dir scikit-learn==0.22.2 && \\\r\n",
        "    pip install --no-cache-dir pandas==0.25.3\r\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633340261185
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define your environment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Environment\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import DockerConfiguration\r\n",
        "\r\n",
        "env = Environment(name='lab04_environment')\r\n",
        "#Creates the environment inside a Docker container\r\n",
        "env.docker.enabled = True #Still working but deprecated\r\n",
        "#Set base image to None, because the image is defined by dockerfile\r\n",
        "env.docker.base_image = None\r\n",
        "env.docker.base_dockerfile = dockerfile\r\n",
        "#To deactivate Conda and only use the packages you need/want\r\n",
        "env.python.user_managed_dependencies=True\r\n",
        "#With a custom Docker image you have to specify the inferencing stack version added to the image which is the latest\r\n",
        "env.inferencing_stack_version='latest'\r\n",
        "#Register your custom environment for further use\r\n",
        "env.register(workspace=ws)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633340264950
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now **look at the output field \"baseDockerfile\"**. You cas observe that your customizations has been taken in account."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define your inference configuration"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inference configuration (docker image, environment of the inference service)\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "\r\n",
        "lab04_inference_config = InferenceConfig(\r\n",
        "    environment=env,\r\n",
        "    source_directory='./sources/',\r\n",
        "    entry_script='scoring_script.py',\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633340393655
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deploy on your custom environment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Deployment configuration\r\n",
        "\r\n",
        "Machine size, CPU, GPU, i.e. the compute target requested by your Web Service"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import LocalWebservice\r\n",
        "\r\n",
        "deployment_config = LocalWebservice.deploy_configuration(port=6789)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633340396559
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Deployment itself\r\n",
        "\r\n",
        "Genreates a Docker build context\r\n",
        "\r\n",
        "*Note*: **It make take between 1 and 2 minutes**.\r\n",
        "\r\n",
        "*Note*: If you want to store and manage your custom Docker containers - for instance using push and pull Docker commands to store them then get them back, you will have to use a new resource: the [Azure container registry](https://docs.microsoft.com/en-us/azure/container-registry/container-registry-get-started-portal)."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service = Model.deploy(\r\n",
        "    ws,\r\n",
        "    'covid19-survival-pred-local-test',\r\n",
        "    [model],\r\n",
        "    lab04_inference_config,\r\n",
        "    deployment_config,\r\n",
        "    overwrite=True,\r\n",
        ")\r\n",
        "service.wait_for_deployment(show_output=True)\r\n",
        "\r\n",
        "print(service.get_logs())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633340490592
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Quick testing of your service in this environment\r\n",
        "\r\n",
        "Now open the terminal and run the following command :\r\n",
        "\r\n",
        "*curl -X POST -d '{\"X_test\":\\[0, 1, 2, 1, 0, 1\\]}' -H \"Content-Type: application/json\" http://localhost:6789/score*\r\n",
        "\r\n",
        "Now try with someone way older (change the \"2\" - age bean 20-30 by an \"8\" - age bean for the 80+ years old) and you will observe that the odds about survival are not the same.\r\n",
        "*curl -X POST -d '{\"X_test\":\\[0, 1, 8, 1, 0, 1\\]}' -H \"Content-Type: application/json\" http://localhost:6789/score*\r\n",
        "\r\n",
        "*Note*: Just as a reminder, the values passed in the list for the inference are (in this order): \\[current_status, sex, age_group, hosp_yn, icu_yn, medcond_yn\\]"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2 - Pinning packages versions with requirements.txt\r\n",
        "\r\n",
        "### Define packages versions\r\n",
        "\r\n",
        "You can pin each package versions in a requirements.txt file\r\n",
        "\r\n",
        "Pinning the exact version of the packages you use allows you to run some reproductible experiences, collaborate with others avoiding environment discrepancies, or issues if a library you use releases a new version that breaks your running scripts."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\r\n",
        "    azureml-defaults\r\n",
        "    azureml.core==1.27.0\r\n",
        "    pip==20.1.1\r\n",
        "    scikit-learn==0.22.2\r\n",
        "    pandas==0.25.3"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now let's use requirements.txt to pin your packages versions, build and deploy your environment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Environment using requirements.txt\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "\r\n",
        "env = Environment.from_pip_requirements(name='lab04_environment', file_path='requirements.txt')\r\n",
        "env.register(workspace=ws)\r\n",
        "lab04_inference_config = InferenceConfig(\r\n",
        "    environment=env,\r\n",
        "    source_directory='./sources/',\r\n",
        "    entry_script='scoring_script.py',\r\n",
        ")\r\n",
        "from azureml.core.webservice import LocalWebservice\r\n",
        "deployment_config = LocalWebservice.deploy_configuration(port=6789)\r\n",
        "service = Model.deploy(\r\n",
        "    ws,\r\n",
        "    'covid19-survival-pred-local-test',\r\n",
        "    [model],\r\n",
        "    lab04_inference_config,\r\n",
        "    deployment_config,\r\n",
        "    overwrite=True,\r\n",
        ")\r\n",
        "service.wait_for_deployment(show_output=True)\r\n",
        "print(service.get_logs())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633340641450
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Quick testing of your service in this environment\r\n",
        "\r\n",
        "Now open the terminal and run the following command :\r\n",
        "\r\n",
        "*curl -X POST -d '{\"X_test\":\\[0, 1, 2, 1, 0, 1\\]}' -H \"Content-Type: application/json\" http://localhost:6789/score*\r\n",
        "\r\n",
        "Now try with someone way older (change the \"2\" - age bean 20-30 by an \"8\" - age bean for the 80+ years old) and you will observe that the odds about survival are not the same.\r\n",
        "*curl -X POST -d '{\"X_test\":\\[0, 1, 8, 1, 0, 1\\]}' -H \"Content-Type: application/json\" http://localhost:6789/score*\r\n",
        "\r\n",
        "*Note*: Just as a reminder, the values passed in the list for the inference are (in this order): \\[current_status, sex, age_group, hosp_yn, icu_yn, medcond_yn\\]"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
