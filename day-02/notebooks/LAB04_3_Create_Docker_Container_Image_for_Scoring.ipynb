{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2 - Create a Docker container image for scoring\r\n",
        "\r\n",
        "## Task 1 - Test locally with Local Web service Compute target"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#REGISTER MODEL TO WORK WITH IT (deploy it)----------\r\n",
        "#Connect to your workspace\r\n",
        "from azureml.core import Workspace\r\n",
        "ws = Workspace.from_config()\r\n",
        "from azureml.core.model import Model\r\n",
        "\r\n",
        "#Register your model\r\n",
        "model = Model.register(model_path=r'./outputs/models/DecisionTreeClassifier.pkl',\r\n",
        "                       model_name=\"DecisionTreeClassifier\",\r\n",
        "                       tags={'area': 'covid19', 'type': 'classification'},\r\n",
        "                       description='Survival to Covid-19 classification and estimation',\r\n",
        "                       workspace=ws)\r\n",
        "\r\n",
        "#Verification of the model\r\n",
        "print(model.name, model.id, model.version, sep='\\t')\r\n",
        "#----------------------------------------------------"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632040842142
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Script to test the deployment and the model\r\n",
        "\r\n",
        "Note that %%writefile is NOT a Python magic but a command of Jupyter Notebook. Avoid commenting before the %%writefile command, it would break the behavior of this command."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ./sources/scoring_script.py\r\n",
        "\r\n",
        "import json\r\n",
        "import pickle as pkl\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "def init():\r\n",
        "    from azureml.core.model import Model\r\n",
        "    global model\r\n",
        "    model_name = 'DecisionTreeClassifier'\r\n",
        "    model_path = Model.get_model_path(model_name=model_name)\r\n",
        "    model = pkl.load(open(model_path, 'rb'))\r\n",
        "\r\n",
        "def run(data):\r\n",
        "    test = json.loads(data)\r\n",
        "    result = model.predict(np.array(test[\"X_test\"]).reshape(-1, 6)).tolist()\r\n",
        "    return result"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631881988963
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Environment\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.environment import CondaDependencies\r\n",
        "\r\n",
        "env = Environment(name='lab04_environment')\r\n",
        "conda_dep = CondaDependencies()\r\n",
        "conda_dep.add_conda_package(\"scikit-learn\")\r\n",
        "conda_dep.add_conda_package(\"pandas\")\r\n",
        "env.python.conda_dependencies=conda_dep\r\n",
        "#Register your custom environment for further use\r\n",
        "env.register(workspace=ws)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632040879398
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inference configuration (docker image, environment of the inference service)\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "\r\n",
        "lab04_inference_config = InferenceConfig(\r\n",
        "    environment=env,\r\n",
        "    source_directory='./sources/',\r\n",
        "    entry_script='scoring_script.py',\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632040884644
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#deployment configuration (machine size, CPU, GPU, i.e. the compute target requested by your Web Service)\r\n",
        "from azureml.core.webservice import LocalWebservice\r\n",
        "\r\n",
        "deployment_config = LocalWebservice.deploy_configuration(port=6789)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632040886057
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Deployment : Genreates a Docker build context\r\n",
        "service = Model.deploy(\r\n",
        "    ws,\r\n",
        "    'covid19-survival-pred-local-test',\r\n",
        "    [model],\r\n",
        "    lab04_inference_config,\r\n",
        "    deployment_config,\r\n",
        "    overwrite=True,\r\n",
        ")\r\n",
        "service.wait_for_deployment(show_output=True)\r\n",
        "\r\n",
        "#Deployment logs\r\n",
        "print(service.get_logs())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632040930155
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now open the terminal and run the following command :\r\n",
        "\r\n",
        "*curl -X POST -d '{\"X_test\":\\[0, 1, 2, 1, 0, 1\\]}' -H \"Content-Type: application/json\" http://localhost:6789/score*\r\n",
        "\r\n",
        "Now try with someone way older (change the \"2\" - age bean 20-30 by an \"8\" - age bean for the 80+ years old) and you will observe that the odds about survival are not the same.\r\n",
        "*curl -X POST -d '{\"X_test\":\\[0, 1, 8, 1, 0, 1\\]}' -H \"Content-Type: application/json\" http://localhost:6789/score*\r\n",
        "\r\n",
        "*Note*: Just as a reminder, the values passed in the list for the inference are (in this order): \\[current_status, sex, age_group, hosp_yn, icu_yn, medcond_yn\\]"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2 - Deploy on managed compute and test live"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\r\n",
        "ws = Workspace.from_config()\r\n",
        "\r\n",
        "from azureml.core.compute import AksCompute, ComputeTarget\r\n",
        "from azureml.core.webservice import AksWebservice\r\n",
        "\r\n",
        "# Use the default configuration (you can also provide parameters to customize this)\r\n",
        "prov_config = AksCompute.provisioning_configuration()\r\n",
        "\r\n",
        "aks_name = 'akscovidcluster'\r\n",
        "# Create the cluster\r\n",
        "aks_target = ComputeTarget.create(workspace = ws,\r\n",
        "                                    name = aks_name,\r\n",
        "                                    provisioning_configuration = prov_config)\r\n",
        "\r\n",
        "# Wait for the create process to complete\r\n",
        "aks_target.wait_for_completion(show_output = True)\r\n",
        "\r\n",
        "aks_target = AksCompute(ws, aks_name)\r\n",
        "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\r\n",
        "service = Model.deploy(ws, 'akscovidservice', [model], lab04_inference_config, deployment_config, aks_target)\r\n",
        "service.wait_for_deployment(show_output = True)\r\n",
        "print(service.state)\r\n",
        "print(service.get_logs())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631970117685
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now go to the test interface of your newly created real-time endpoint, named \"akscovidservice\", choose the \"Test\" tab, and copy / paste the following data in the capture box: *{\"X_test\":\\[0, 1, 2, 1, 0, 1\\]}*\r\n",
        "\r\n",
        "*Note*: Just as a reminder, the values passed in the list for the inference are (in this order): \\[current_status, sex, age_group, hosp_yn, icu_yn, medcond_yn\\]"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now try to call your Web Service in Python\r\n",
        "\r\n",
        "BEWARE: You will have to change the api_key with your own one. You can find it when you edit your endpoint and open the \"Consume\" tab. The api_key is named under \"Primary key\". You can for security purposes regenerate it. When you do that, you can use the second key temporarily while the primary one is re-generating, in order to not interrupt your service."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\r\n",
        "import json\r\n",
        "import os\r\n",
        "import ssl\r\n",
        "\r\n",
        "def allowSelfSignedHttps(allowed):\r\n",
        "    # bypass the server certificate verification on client side\r\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\r\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\r\n",
        "\r\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\r\n",
        "\r\n",
        "# Request data goes here\r\n",
        "data = {\"X_test\":[0, 1, 2, 1, 0, 1]}\r\n",
        "\r\n",
        "body = str.encode(json.dumps(data))\r\n",
        "\r\n",
        "url = 'http://20.75.130.25:80/api/v1/service/akscovidservice/score'\r\n",
        "api_key = 'qGnjLJCsoJBlQs6wn01PWQl5oqnF2CjS' # Replace this with the API key for the web service\r\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\r\n",
        "\r\n",
        "req = urllib.request.Request(url, body, headers)\r\n",
        "\r\n",
        "try:\r\n",
        "    response = urllib.request.urlopen(req)\r\n",
        "\r\n",
        "    result = response.read()\r\n",
        "    print(result)\r\n",
        "except urllib.error.HTTPError as error:\r\n",
        "    print(\"The request failed with status code: \" + str(error.code))\r\n",
        "\r\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\r\n",
        "    print(error.info())\r\n",
        "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631970397465
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3 - Deploy custom Docker container image with managed compute\r\n",
        "\r\n",
        "## Task 1 - Deploy custom Docker container image with managed compute"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define packages versions\r\n",
        "\r\n",
        "You can pin each package versions in a requirements.txt file\r\n",
        "\r\n",
        "Pinning the exact version of the packages you use allows you to run some reproductible experiences, collaborate with others avoiding environment discrepancies, or issues if a library you use releases a new version that breaks your running scripts.\r\n",
        "\r\n",
        "*Note*: In this task, we will not use this requirements file for other purposes than listing our packages versions. The installation of the packages themselves, within the environment, will be managed through a dockerfile in this exercise.\r\n",
        "We will use this file in a more concrete manner in the Task 2 of this exercise."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\r\n",
        "    azureml-defaults\r\n",
        "    azureml.core==1.27.0\r\n",
        "    pip==20.1.1\r\n",
        "    scikit-learn==0.22.2\r\n",
        "    pandas==0.25.3"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a custom Docker container image\r\n",
        "\r\n",
        "*Note* that you can also cherry-pick among the Docker images provided by Azure. We recommend custom Docker images in case you need to install non-Python packages as dependencies"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#WRITE YOUR DOCKER FILE------------------------------\r\n",
        "#Note that the dockerfile is here written as a string and not as a file.\r\n",
        "#It works as well, and for more permanent, usual and collabotrative process\r\n",
        "#we would rather recommend that you write it down as a file containing all\r\n",
        "#these steps in a more permanent and \"portable\" location. Anyway it will be done\r\n",
        "#when you will register your environment\r\n",
        "dockerfile = r\"\"\"\r\n",
        "FROM mcr.microsoft.com/mlops/python:latest\r\n",
        "#Install the dependancies\r\n",
        "RUN pip install --no-cache-dir --upgrade pip && \\\r\n",
        "    pip install --no-cache-dir azureml-defaults && \\\r\n",
        "    pip install --no-cache-dir azureml-core==1.27.0 &&\\\r\n",
        "    pip install --no-cache-dir scikit-learn==0.22.2 && \\\r\n",
        "    pip install --no-cache-dir pandas==0.25.3\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "#You have now all you need to create your own docker image within your environment\r\n",
        "\r\n",
        "#----------------------------------------------------"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632040862700
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define your environment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Environment\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import DockerConfiguration\r\n",
        "\r\n",
        "env = Environment(name='lab04_environment')\r\n",
        "#Creates the environment inside a Docker container\r\n",
        "env.docker.enabled = True #Still working but deprecated\r\n",
        "#Set base image to None, because the image is defined by dockerfile\r\n",
        "env.docker.base_image = None\r\n",
        "env.docker.base_dockerfile = dockerfile\r\n",
        "#To deactivate Conda and only use the packages you need/want\r\n",
        "env.python.user_managed_dependencies=True\r\n",
        "#With a custom Docker image you have to specify the inferencing stack version added to the image which is the latest\r\n",
        "env.inferencing_stack_version='latest'\r\n",
        "#Register your custom environment for further use\r\n",
        "env.register(workspace=ws)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632040865622
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inference configuration (docker image, environment of the inference service)\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "\r\n",
        "lab04_inference_config = InferenceConfig(\r\n",
        "    environment=env,\r\n",
        "    source_directory='./sources/',\r\n",
        "    entry_script='scoring_script.py',\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631970673539
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#deployment configuration (machine size, CPU, GPU, i.e. the compute target requested by your Web Service)\r\n",
        "from azureml.core.webservice import LocalWebservice\r\n",
        "\r\n",
        "deployment_config = LocalWebservice.deploy_configuration(port=6789)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631970676991
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Deployment : Genreates a Docker build context\r\n",
        "service = Model.deploy(\r\n",
        "    ws,\r\n",
        "    'covid19-survival-pred-local-test',\r\n",
        "    [model],\r\n",
        "    lab04_inference_config,\r\n",
        "    deployment_config,\r\n",
        "    overwrite=True,\r\n",
        ")\r\n",
        "service.wait_for_deployment(show_output=True)\r\n",
        "\r\n",
        "print(service.get_logs())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631970740392
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now open the terminal and run the following command :\r\n",
        "\r\n",
        "*curl -X POST -d '{\"X_test\":\\[0, 1, 2, 1, 0, 1\\]}' -H \"Content-Type: application/json\" http://localhost:6789/score*\r\n",
        "\r\n",
        "Now try with someone way older (change the \"2\" - age bean 20-30 by an \"8\" - age bean for the 80+ years old) and you will observe that the odds about survival are not the same.\r\n",
        "*curl -X POST -d '{\"X_test\":\\[0, 1, 8, 1, 0, 1\\]}' -H \"Content-Type: application/json\" http://localhost:6789/score*\r\n",
        "\r\n",
        "*Note*: Just as a reminder, the values passed in the list for the inference are (in this order): \\[current_status, sex, age_group, hosp_yn, icu_yn, medcond_yn\\]"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2 - Pinning packages versions with requirements.txt\r\n",
        "\r\n",
        "#### Let's use requirements.txt to pin your packages versions, build and deploy your environment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Environment using requirements.txt\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "\r\n",
        "env = Environment.from_pip_requirements(name='lab04_environment', file_path='requirements.txt')\r\n",
        "env.register(workspace=ws)\r\n",
        "lab04_inference_config = InferenceConfig(\r\n",
        "    environment=env,\r\n",
        "    source_directory='./sources/',\r\n",
        "    entry_script='scoring_script.py',\r\n",
        ")\r\n",
        "from azureml.core.webservice import LocalWebservice\r\n",
        "deployment_config = LocalWebservice.deploy_configuration(port=6789)\r\n",
        "service = Model.deploy(\r\n",
        "    ws,\r\n",
        "    'covid19-survival-pred-local-test',\r\n",
        "    [model],\r\n",
        "    lab04_inference_config,\r\n",
        "    deployment_config,\r\n",
        "    overwrite=True,\r\n",
        ")\r\n",
        "service.wait_for_deployment(show_output=True)\r\n",
        "print(service.get_logs())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631971014894
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now open the terminal and run the following command :\r\n",
        "\r\n",
        "*curl -X POST -d '{\"X_test\":\\[0, 1, 2, 1, 0, 1\\]}' -H \"Content-Type: application/json\" http://localhost:6789/score*\r\n",
        "\r\n",
        "Now try with someone way older (change the \"2\" - age bean 20-30 by an \"8\" - age bean for the 80+ years old) and you will observe that the odds about survival are not the same.\r\n",
        "*curl -X POST -d '{\"X_test\":\\[0, 1, 8, 1, 0, 1\\]}' -H \"Content-Type: application/json\" http://localhost:6789/score*\r\n",
        "\r\n",
        "*Note*: Just as a reminder, the values passed in the list for the inference are (in this order): \\[current_status, sex, age_group, hosp_yn, icu_yn, medcond_yn\\]"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}